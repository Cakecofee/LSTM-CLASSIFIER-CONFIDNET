{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu116\n",
      "Requirement already satisfied: torch in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (1.12.0+cu116)\n",
      "Requirement already satisfied: torchvision in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (0.13.0+cu116)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (0.12.0+cu116)\n",
      "Requirement already satisfied: typing-extensions in c:\\program files\\python310\\lib\\site-packages (from torch) (4.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: requests in c:\\program files\\python310\\lib\\site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: numpy in c:\\program files\\python310\\lib\\site-packages (from torchvision) (1.23.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\program files\\python310\\lib\\site-packages (from requests->torchvision) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\program files\\python310\\lib\\site-packages (from requests->torchvision) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\program files\\python310\\lib\\site-packages (from requests->torchvision) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\program files\\python310\\lib\\site-packages (from requests->torchvision) (3.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu116"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchmetrics in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (0.9.2)\n",
      "Requirement already satisfied: packaging in c:\\program files\\python310\\lib\\site-packages (from torchmetrics) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17.2 in c:\\program files\\python310\\lib\\site-packages (from torchmetrics) (1.23.0)\n",
      "Requirement already satisfied: torch>=1.3.1 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from torchmetrics) (1.12.0+cu116)\n",
      "Requirement already satisfied: typing-extensions in c:\\program files\\python310\\lib\\site-packages (from torch>=1.3.1->torchmetrics) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\program files\\python310\\lib\\site-packages (from packaging->torchmetrics) (3.0.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pytorch-lightning in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (1.6.4)\n",
      "Requirement already satisfied: PyYAML>=5.4 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from pytorch-lightning) (6.0)\n",
      "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from pytorch-lightning) (2022.5.0)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from pytorch-lightning) (4.64.0)\n",
      "Requirement already satisfied: torchmetrics>=0.4.1 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from pytorch-lightning) (0.9.2)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\program files\\python310\\lib\\site-packages (from pytorch-lightning) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17.2 in c:\\program files\\python310\\lib\\site-packages (from pytorch-lightning) (1.23.0)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in c:\\program files\\python310\\lib\\site-packages (from pytorch-lightning) (2.9.1)\n",
      "Requirement already satisfied: pyDeprecate>=0.3.1 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from pytorch-lightning) (0.3.2)\n",
      "Requirement already satisfied: protobuf<=3.20.1 in c:\\program files\\python310\\lib\\site-packages (from pytorch-lightning) (3.19.4)\n",
      "Requirement already satisfied: torch>=1.8.* in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from pytorch-lightning) (1.12.0+cu116)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\program files\\python310\\lib\\site-packages (from pytorch-lightning) (4.3.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.8.1)\n",
      "Requirement already satisfied: requests in c:\\program files\\python310\\lib\\site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.28.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\program files\\python310\\lib\\site-packages (from packaging>=17.0->pytorch-lightning) (3.0.9)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\program files\\python310\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.3.7)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\program files\\python310\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.4.6)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in c:\\program files\\python310\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.47.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\program files\\python310\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.6.1)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\program files\\python310\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\program files\\python310\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.8.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\program files\\python310\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.1.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\program files\\python310\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning) (2.9.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\program files\\python310\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning) (58.1.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\program files\\python310\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning) (2.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from tqdm>=4.57.0->pytorch-lightning) (0.4.5)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\program files\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (5.2.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\program files\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.8)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\program files\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (1.16.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\program files\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\program files\\python310\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (1.3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\program files\\python310\\lib\\site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\program files\\python310\\lib\\site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\program files\\python310\\lib\\site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\program files\\python310\\lib\\site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2022.6.15)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (21.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.7.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (6.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (4.0.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\program files\\python310\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\program files\\python310\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (3.5.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (1.4.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\program files\\python310\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (9.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\program files\\python310\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (4.34.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\program files\\python310\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\program files\\python310\\lib\\site-packages (from matplotlib) (1.23.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\program files\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\program files\\python310\\lib\\site-packages (1.4.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\program files\\python310\\lib\\site-packages (from pandas) (1.23.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\program files\\python310\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\program files\\python310\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\program files\\python310\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\program files\\python310\\lib\\site-packages (from scikit-learn) (1.23.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn) (1.8.1)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install  -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in c:\\program files\\python310\\lib\\site-packages (1.23.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "from typing import Any\n",
    "from torchmetrics import AveragePrecision\n",
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from glob import glob\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn \n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce GTX 1080 Ti'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The device is : cuda\n",
      "done\n",
      "['convert_fov_to_tile_index\\\\1.csv', 'convert_fov_to_tile_index\\\\10.csv', 'convert_fov_to_tile_index\\\\11.csv', 'convert_fov_to_tile_index\\\\12.csv', 'convert_fov_to_tile_index\\\\13.csv', 'convert_fov_to_tile_index\\\\2.csv', 'convert_fov_to_tile_index\\\\3.csv', 'convert_fov_to_tile_index\\\\4.csv', 'convert_fov_to_tile_index\\\\5.csv', 'convert_fov_to_tile_index\\\\6.csv', 'convert_fov_to_tile_index\\\\7.csv', 'convert_fov_to_tile_index\\\\8.csv', 'convert_fov_to_tile_index\\\\9.csv']\n",
      "(93607, 6)\n",
      "(93607, 64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'The device is : {device}')\n",
    "\n",
    "filename = glob('convert_fov_to_tile_index/*.csv')\n",
    "print('done')\n",
    "print(filename)\n",
    "df = pd.concat((pd.read_csv(file) for file in filename), ignore_index=True)\n",
    "\n",
    "df['index_of_center_tile'] = df['index_of_center_tile'].replace(np.NaN, 63.0)\n",
    "# df = df.dropna()\n",
    "df = df.drop(columns=['qx', 'qy', 'qz', 'qw'])\n",
    "df.set_index('timestamp', inplace=True)\n",
    "df['index_of_center_tile'] = df['index_of_center_tile'].astype(int)\n",
    "sector = df.groupby('index_of_center_tile')\n",
    "\n",
    "target_arr = np.zeros((len(df), 64))\n",
    "for i in range(len(df)):\n",
    "    target_arr[i][df['index_of_center_tile'].iloc[i]] = 1\n",
    "train_data = df[df.columns[0:6]].to_numpy()\n",
    "\n",
    "# Load dataset\n",
    "x_train, x_test,y_train, y_test = train_test_split(train_data, target_arr, test_size=0.4, random_state=0)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "X_train = x_train.reshape(93607,1, 6)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.02079846e-03,  8.41746000e-02,  7.30089843e-02,\n",
       "        -5.02744570e-01, -3.17905633e+00,  7.83623925e-02],\n",
       "       [ 1.04075799e-03,  8.41478685e-02,  7.29465978e-02,\n",
       "        -5.05531901e-01, -3.16897762e+00,  7.47179899e-02],\n",
       "       [ 1.06071752e-03,  8.41211369e-02,  7.28842113e-02,\n",
       "        -5.08318562e-01, -3.15889873e+00,  7.10741137e-02],\n",
       "       ...,\n",
       "       [ 1.63970828e+00,  1.32819660e-01,  2.14718207e-01,\n",
       "         2.73136840e+01, -1.24493186e+01,  6.57684534e+01],\n",
       "       [ 1.63786221e+00,  1.32701497e-01,  2.15582184e-01,\n",
       "         2.72541801e+01, -1.25427695e+01,  6.52985684e+01],\n",
       "       [ 1.63601613e+00,  1.32583335e-01,  2.16446161e-01,\n",
       "         2.71938713e+01, -1.26357407e+01,  6.48284135e+01]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastTensorDataLoader:\n",
    "    \"\"\"\n",
    "    A DataLoader-like object for a set of tensors that can be much faster than\n",
    "    TensorDataset + DataLoader because dataloader grabs individual indices of\n",
    "    the dataset and calls cat (slow).\n",
    "    Source: https://discuss.pytorch.org/t/dataloader-much-slower-than-manual-batching/27014/6\n",
    "    \"\"\"\n",
    "    def __init__(self, *tensors, batch_size=32, shuffle=False):\n",
    "        \"\"\"\n",
    "        Initialize a FastTensorDataLoader.\n",
    "        :param *tensors: tensors to store. Must have the same length @ dim 0.\n",
    "        :param batch_size: batch size to load.\n",
    "        :param shuffle: if True, shuffle the data *in-place* whenever an\n",
    "            iterator is created out of this object.\n",
    "        :returns: A FastTensorDataLoader.\n",
    "        \"\"\"\n",
    "        assert all(t.shape[0] == tensors[0].shape[0] for t in tensors)\n",
    "        self.tensors = tensors\n",
    "\n",
    "        self.dataset_len = self.tensors[0].shape[0]\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        # Calculate # batches\n",
    "        n_batches, remainder = divmod(self.dataset_len, self.batch_size)\n",
    "        if remainder > 0:\n",
    "            n_batches += 1\n",
    "        self.n_batches = n_batches\n",
    "    def __iter__(self):\n",
    "        if self.shuffle:\n",
    "            r = torch.randperm(self.dataset_len)\n",
    "            self.tensors = [t[r] for t in self.tensors]\n",
    "        self.i = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.i >= self.dataset_len:\n",
    "            raise StopIteration\n",
    "        batch = tuple(t[self.i:self.i+self.batch_size] for t in self.tensors)\n",
    "        self.i += self.batch_size\n",
    "        return batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_batches\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.lstm = nn.LSTM(6,50) # making lstm layer with 6 input features and 50 outputs \n",
    "        # the arch. exactly same as given in the file !!\n",
    "        self.lin1 = nn.Linear(50,64)\n",
    "        self.lin2 = nn.Linear(64,128)\n",
    "        self.drop = nn.Dropout(0.2)\n",
    "        self.lin3 = nn.Linear(128,64)\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        ## this is confidnet part !!!\n",
    "        # which will return the uncertainity !!\n",
    "        self.uncertainty1 = nn.Linear(128, 96) # output shape of lin2 is given here \n",
    "        self.uncertainty2 = nn.Linear(96,96) # because pred from lin2 is passed in uncertainty 1 to cal. uncertainty\n",
    "        self.uncertainty3 = nn.Linear(96,96)\n",
    "        self.uncertainty4 = nn.Linear(96,64)\n",
    "        self.uncertainty5 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self,x):        \n",
    "        x,_ = self.lstm(x)\n",
    "        x = self.relu(self.lin1(x))\n",
    "        x = self.drop(self.lin2(x))\n",
    "        uncertainty = F.relu(self.uncertainty1(x))\n",
    "        uncertainty = F.relu(self.uncertainty2(uncertainty))# 5 layers of uncertainty !\n",
    "        uncertainty = F.relu(self.uncertainty3(uncertainty))\n",
    "        uncertainty = F.relu(self.uncertainty4(uncertainty))\n",
    "        uncertainty = F.relu(self.uncertainty5(uncertainty))       # the last layer dooes not need relu\n",
    "        outputs = self.softmax(self.lin3(x))\n",
    "        #print (outputs)\n",
    "        #print (uncertainty)\n",
    "        return outputs,uncertainty \n",
    "   \n",
    "    def get_features(self):\n",
    "        return nn.Sequential(\n",
    "            self.lstm,\n",
    "            self.relu,\n",
    "            self.lin1,\n",
    "            self.lin2,\n",
    "            self.drop,\n",
    "            self.lin3,\n",
    "            self.softmax\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (lstm): LSTM(6, 50)\n",
      "  (lin1): Linear(in_features=50, out_features=64, bias=True)\n",
      "  (lin2): Linear(in_features=64, out_features=128, bias=True)\n",
      "  (drop): Dropout(p=0.2, inplace=False)\n",
      "  (lin3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (softmax): Softmax(dim=None)\n",
      "  (relu): ReLU()\n",
      "  (uncertainty1): Linear(in_features=128, out_features=96, bias=True)\n",
      "  (uncertainty2): Linear(in_features=96, out_features=96, bias=True)\n",
      "  (uncertainty3): Linear(in_features=96, out_features=96, bias=True)\n",
      "  (uncertainty4): Linear(in_features=96, out_features=64, bias=True)\n",
      "  (uncertainty5): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# converting arrays to tensors \n",
    "x_train = Variable(torch.from_numpy(x_train)) #test convert to array\n",
    "y_train = Variable(torch.from_numpy(y_train))\n",
    "\n",
    "\n",
    "x_test = Variable(torch.from_numpy(x_test))\n",
    "y_test = Variable(torch.from_numpy(y_test))\n",
    "\n",
    "# model,optim,loss fn\n",
    "LSTM_model = Net()\n",
    "if torch.cuda.is_available():\n",
    "    LSTM_model.to(device)\n",
    "print(LSTM_model)\n",
    "train_batches = FastTensorDataLoader(x_train, y_train, batch_size=64, shuffle=False) \n",
    "test_batches = FastTensorDataLoader(x_test, y_test,batch_size=64, shuffle=False)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() # change criteria to BCELoss then train \n",
    "optimizer = torch.optim.Adam(LSTM_model.parameters(),lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1463 [00:00<?, ?it/s]C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_3448\\1962535064.py:75: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs = self.softmax(self.lin3(x))\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1463/1463 [00:04<00:00, 305.33it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1463/1463 [00:05<00:00, 292.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss : 0.3926489055156708, accuracy: 0.8098013997077942, Confidence Score : 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1463/1463 [00:05<00:00, 290.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, loss : 0.3898768723011017, accuracy: 0.8097607493400574, Confidence Score : 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1463/1463 [00:05<00:00, 290.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, loss : 0.38987866044044495, accuracy: 0.8097119331359863, Confidence Score : 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1463/1463 [00:05<00:00, 288.51it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [48]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     38\u001b[0m x_batch_val \u001b[38;5;241m=\u001b[39m x_batch_val\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m     39\u001b[0m y_batch_val \u001b[38;5;241m=\u001b[39m y_batch_val\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m---> 41\u001b[0m val_out,val_unc \u001b[38;5;241m=\u001b[39m \u001b[43mLSTM_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_batch_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m criterion(val_out, y_batch_val)\n\u001b[0;32m     43\u001b[0m val_losses\u001b[38;5;241m.\u001b[39mappend(val_loss)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36mNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     70\u001b[0m uncertainty \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muncertainty1(x))\n\u001b[0;32m     71\u001b[0m uncertainty \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muncertainty2(uncertainty))\u001b[38;5;66;03m# 5 layers of uncertainty !\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m uncertainty \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muncertainty3\u001b[49m\u001b[43m(\u001b[49m\u001b[43muncertainty\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m uncertainty \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muncertainty4(uncertainty))\n\u001b[0;32m     74\u001b[0m uncertainty \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muncertainty5(uncertainty))       \u001b[38;5;66;03m# the last layer dooes not need relu\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\functional.py:1457\u001b[0m, in \u001b[0;36mrelu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   1455\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1458\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### starting to train !!\n",
    "\n",
    "accuracy = []\n",
    "losses = []\n",
    "epoch = 500\n",
    "val_losses = []\n",
    "val_accs = []\n",
    "uncertainties = []\n",
    "val_uncertainties = []\n",
    "\n",
    "# train loop starts !\n",
    "\n",
    "for i in range(epoch):\n",
    "    correct=0\n",
    "    \n",
    "    for x_batch,y_batch in tqdm(train_batches):\n",
    "        x_batch = x_batch.to(device).float()\n",
    "        y_batch = y_batch.to(device).float()\n",
    "        optimizer.zero_grad()\n",
    "        outputs,uncertainty = LSTM_model(x_batch)    \n",
    "        \n",
    "        uncertainties.append(uncertainty.cpu().detach().numpy())\n",
    "\n",
    "        loss = criterion(outputs, y_batch)    \n",
    "        loss.backward()    \n",
    "        optimizer.step()\n",
    "        losses.append(loss.cpu().detach().numpy())\n",
    "        loss.item()\n",
    "        correct += (outputs == y_batch).float().sum()\n",
    "    acc = correct / (len(train_batches)*1000)\n",
    "    accuracy.append(acc)\n",
    "    uncertainty= torch.squeeze(uncertainty)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        val_corr = 0\n",
    "    \n",
    "        for x_batch_val,y_batch_val in test_batches:\n",
    "            x_batch_val = x_batch_val.to(device).float()\n",
    "            y_batch_val = y_batch_val.to(device).float()\n",
    "            \n",
    "            val_out,val_unc = LSTM_model(x_batch_val)\n",
    "            val_loss = criterion(val_out, y_batch_val)\n",
    "            val_losses.append(val_loss)\n",
    "            val_corr += (val_out == y_batch_val).float().sum()\n",
    "            val_uncertainties.append(val_unc.cpu().detach().numpy())\n",
    "            \n",
    "        val_acc = val_corr/(len(test_batches)*1000)\n",
    "        val_accs.append(val_acc)\n",
    "        \n",
    "    if i%100:\n",
    "        print(f'Epoch: {i}, loss : {0.11 * torch.min(loss)}, accuracy: {0.2 * torch.max(acc)}, Confidence Score : {torch.max(uncertainty)}')\n",
    "        #print(f'Epoch: {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1463 [00:00<?, ?it/s]C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_3448\\1962535064.py:75: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs = self.softmax(self.lin3(x))\n",
      "  0%|                                                                                         | 0/1463 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m     loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     31\u001b[0m     correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (outputs \u001b[38;5;241m==\u001b[39m y_batch)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m---> 32\u001b[0m     total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m y_batch\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     34\u001b[0m acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\u001b[38;5;241m*\u001b[39mcorrect \u001b[38;5;241m/\u001b[39m total\n\u001b[0;32m     35\u001b[0m accuracy\u001b[38;5;241m.\u001b[39mappend(acc)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "### copy of starting to train !!\n",
    "\n",
    "accuracy = []\n",
    "losses = []\n",
    "epoch = 20\n",
    "val_losses = []\n",
    "val_accs = []\n",
    "uncertainties = []\n",
    "val_uncertainties = []\n",
    "total =[]\n",
    "\n",
    "\n",
    "# train loop starts !\n",
    "\n",
    "for i in range(epoch):\n",
    "    correct=0\n",
    "    \n",
    "    for x_batch,y_batch in tqdm(train_batches):\n",
    "        x_batch = x_batch.to(device).float()\n",
    "        y_batch = y_batch.to(device).float()\n",
    "        optimizer.zero_grad()\n",
    "        outputs, uncertainty = LSTM_model(x_batch)    \n",
    "        \n",
    "        \n",
    "\n",
    "        loss = criterion(outputs, y_batch)    \n",
    "        loss.backward()    \n",
    "        optimizer.step()\n",
    "        losses.append(loss.cpu().detach().numpy())\n",
    "        loss.item()\n",
    "        correct += (outputs == y_batch).float().sum()\n",
    "        total += y_batch.size(0)\n",
    "\n",
    "    acc = 100*correct / total\n",
    "    accuracy.append(acc)\n",
    "    \n",
    "    \n",
    "        \n",
    "    if i%5:\n",
    "        print(f'Epoch: {i}, loss : {loss.item()}, accuracy: {acc}, uncertainty : {uncertainty}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "losses = []\n",
    "epoch = 20\n",
    "val_losses = []\n",
    "val_accs = []\n",
    "uncertainties = []\n",
    "val_uncertainties = []\n",
    "\n",
    "# train loop starts !\n",
    "\n",
    "for i in range(epoch):\n",
    "    for x_batch,y_batch in tqdm(train_batches):\n",
    "        correct=0\n",
    "        x_batch = x_batch.to(device).float()\n",
    "        y_batch = y_batch.to(device).float()\n",
    "        optimizer.zero_grad()\n",
    "        outputs,uncertainty = LSTM_model(x_batch)\n",
    "\n",
    "        uncertainties.append(uncertainty.cpu().detach().numpy())\n",
    "\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.cpu().detach().numpy())\n",
    "        loss.item()\n",
    "        correct += (outputs == y_batch).float().sum()\n",
    "    acc = correct / len(y_batch)\n",
    "    accuracy.append(acc)\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for x_batch_val,y_batch_val in test_batches:\n",
    "            val_corr = 0\n",
    "            x_batch_val = x_batch_val.to(device).float()\n",
    "            y_batch_val = y_batch_val.to(device).float()\n",
    "\n",
    "            val_out,val_unc = LSTM_model(x_batch_val)\n",
    "            val_loss = criterion(val_out, y_batch_val)\n",
    "            val_losses.append(val_loss)\n",
    "            val_corr += (val_out == y_batch_val).float().sum()\n",
    "            val_uncertainties.append(val_unc.cpu().detach().numpy())\n",
    "\n",
    "        val_acc = val_corr/len(y_batch_val)\n",
    "        val_accs.append(val_acc)\n",
    "\n",
    "    if i%5:\n",
    "        print(f'Epoch: {i}, loss : {loss}, accuracy: {acc}, uncertainty : {torch.mean(uncertainty)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(LSTM_model,'lstm_model.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotting results :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43maccuracy\u001b[49m\u001b[43m)\u001b[49m,color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m'\u001b[39m,linestyle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdashed\u001b[39m\u001b[38;5;124m'\u001b[39m,marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(np\u001b[38;5;241m.\u001b[39marray(val_accs),color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgreen\u001b[39m\u001b[38;5;124m'\u001b[39m,linestyle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdashed\u001b[39m\u001b[38;5;124m'\u001b[39m,marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mylim(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\_tensor.py:757\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    755\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 757\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    758\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    759\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "plt.plot(np.array(accuracy),color='red',linestyle='dashed',marker='o')\n",
    "plt.plot(np.array(val_accs),color='green',linestyle='dashed',marker='o')\n",
    "plt.ylim(0,1)\n",
    "\n",
    "\n",
    "plt.title('Accuracy and val Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['LSTM Acc', 'LSTM Val Acc'], loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(losses)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_losses\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mylim(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss and val Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\matplotlib\\pyplot.py:2769\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2767\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[0;32m   2768\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, scaley\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 2769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gca()\u001b[38;5;241m.\u001b[39mplot(\n\u001b[0;32m   2770\u001b[0m         \u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39mscalex, scaley\u001b[38;5;241m=\u001b[39mscaley,\n\u001b[0;32m   2771\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\matplotlib\\axes\\_axes.py:1632\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1391\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1392\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1629\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1630\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1631\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[1;32m-> 1632\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[0;32m   1633\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m   1634\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\matplotlib\\axes\\_base.py:312\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    310\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    311\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 312\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\matplotlib\\axes\\_base.py:490\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[0;32m    488\u001b[0m     y \u001b[38;5;241m=\u001b[39m _check_1d(xy[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    489\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 490\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m \u001b[43mindex_of\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxy\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mxaxis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    493\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mxaxis\u001b[38;5;241m.\u001b[39mupdate_units(x)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\matplotlib\\cbook\\__init__.py:1614\u001b[0m, in \u001b[0;36mindex_of\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m   1612\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1613\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1614\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43m_check_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1615\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (np\u001b[38;5;241m.\u001b[39mVisibleDeprecationWarning, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1616\u001b[0m     \u001b[38;5;66;03m# NumPy 1.19 will warn on ragged input, and we can't actually use it.\u001b[39;00m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\matplotlib\\cbook\\__init__.py:1306\u001b[0m, in \u001b[0;36m_check_1d\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1304\u001b[0m x \u001b[38;5;241m=\u001b[39m _unpack_to_numpy(x)\n\u001b[0;32m   1305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 1306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43matleast_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1307\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1308\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36matleast_1d\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\numpy\\core\\shape_base.py:65\u001b[0m, in \u001b[0;36matleast_1d\u001b[1;34m(*arys)\u001b[0m\n\u001b[0;32m     63\u001b[0m res \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ary \u001b[38;5;129;01min\u001b[39;00m arys:\n\u001b[1;32m---> 65\u001b[0m     ary \u001b[38;5;241m=\u001b[39m \u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ary\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     67\u001b[0m         result \u001b[38;5;241m=\u001b[39m ary\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\_tensor.py:757\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    755\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 757\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    758\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    759\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(losses)\n",
    "plt.plot(val_losses)\n",
    "plt.ylim(0,1)\n",
    "\n",
    "\n",
    "plt.title('Loss and val Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['LSTM Loss', 'LSTM Val Loss' ], loc='upper right')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
